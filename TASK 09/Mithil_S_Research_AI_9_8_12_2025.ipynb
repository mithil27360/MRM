{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "533aec33-7597-44be-9719-d7ce769c9e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f5199f-ae0c-4a25-a313-0a85d72518ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1b89ec-735e-4d96-94b9-29a10a930f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_median = df['Age'].median()\n",
    "df['Age'] = df['Age'].fillna(age_median)\n",
    "embarked_mode = df['Embarked'].mode()[0]\n",
    "df['Embarked'] = df['Embarked'].fillna(embarked_mode)\n",
    "\n",
    "def get_title(name):\n",
    "    title_search = re.search(r' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "df['Title'] = df['Name'].apply(get_title)\n",
    "\n",
    "df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
    "df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "df['Family_Size'] = df['SibSp'] + df['Parch'] + 1\n",
    "df['Is_Alone'] = 0\n",
    "df.loc[df['Family_Size'] == 1, 'Is_Alone'] = 1\n",
    "\n",
    "df['Sex'] = df['Sex'].map({'female': 1, 'male': 0}).astype(int)\n",
    "df = pd.get_dummies(df, columns=['Embarked', 'Title','Is_Alone'], drop_first=True)\n",
    "df = df.drop(['Name', 'Ticket', 'SibSp', 'Parch', 'PassengerId','Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6007fa0-82eb-4918-b8c4-a85c849f3186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, ts=0.2, rs=42):\n",
    "    np.random.seed(rs)\n",
    "    idx = np.arange(X.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "    sp = int((1 - ts) * X.shape[0])\n",
    "    return X[:sp], X[sp:], y[:sp], y[sp:]\n",
    "\n",
    "def norm(X_tr, X_te):\n",
    "    mn = X_tr.min(axis=0)\n",
    "    mx = X_tr.max(axis=0)\n",
    "    X_tr_n = (X_tr - mn) / (mx - mn + 1e-8)\n",
    "    X_te_n = (X_te - mn) / (mx - mn + 1e-8)\n",
    "    return X_tr_n, X_te_n\n",
    "\n",
    "def accuracy(yt, yp):\n",
    "    return np.mean(yt == yp)\n",
    "\n",
    "def precision(yt, yp):\n",
    "    tp = np.sum((yt == 1) & (yp == 1))\n",
    "    fp = np.sum((yt == 0) & (yp == 1))\n",
    "    return tp / (tp + fp + 1e-8)\n",
    "\n",
    "def recall(yt, yp):\n",
    "    tp = np.sum((yt == 1) & (yp == 1))\n",
    "    fn = np.sum((yt == 1) & (yp == 0))\n",
    "    return tp / (tp + fn + 1e-8)\n",
    "\n",
    "def f1_score(yt, yp):\n",
    "    prec = precision(yt, yp)\n",
    "    rec = recall(yt, yp)\n",
    "    return 2 * (prec * rec) / (prec + rec + 1e-8)\n",
    "\n",
    "def confusion_matrix(yt, yp):\n",
    "    tn = np.sum((yt == 0) & (yp == 0))\n",
    "    fp = np.sum((yt == 0) & (yp == 1))\n",
    "    fn = np.sum((yt == 1) & (yp == 0))\n",
    "    tp = np.sum((yt == 1) & (yp == 1))\n",
    "    return np.array([[tn, fp], [fn, tp]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "503c2df9-8e73-4a84-af74-737fdb53285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Survived']).values\n",
    "y = df['Survived'].values\n",
    "X_tr, X_te, y_tr, y_te = split_data(X, y, ts=0.2, rs=42)\n",
    "X_tr_n, X_te_n = norm(X_tr, X_te)\n",
    "X_tr_n = np.array(X_tr_n, dtype=np.float64)\n",
    "y_tr = np.array(y_tr, dtype=np.float64)\n",
    "X_te_n = X_te_n.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a93e7f00-c8f2-448d-99ea-643b58fe5458",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "        self.components = None\n",
    "        self.mean = None\n",
    "        self.explained_variance = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        X_centered = X - self.mean\n",
    "        cov_matrix = np.cov(X_centered.T)\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "        idx = eigenvalues.argsort()[::-1]\n",
    "        eigenvalues = eigenvalues[idx]\n",
    "        eigenvectors = eigenvectors[:, idx]\n",
    "        self.components = eigenvectors[:, :self.n_components]\n",
    "        self.explained_variance = eigenvalues[:self.n_components] / np.sum(eigenvalues)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X_centered = X - self.mean\n",
    "        return np.dot(X_centered, self.components)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "405ff656-57fa-4cfa-b693-a69b245c061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=8)\n",
    "X_tr_pca = pca.fit_transform(X_tr_n)\n",
    "X_te_pca = pca.transform(X_te_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5116549-0052-49d1-8b7b-1588ac967ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orginal :  12\n",
      "reduced: 8\n",
      "explained variance: [0.39486244 0.16463508 0.13487671 0.11752416 0.09083875 0.03631981\n",
      " 0.02893547 0.01408696]\n",
      "cumulative variance: [0.39486244 0.55949752 0.69437423 0.81189839 0.90273715 0.93905696\n",
      " 0.96799242 0.98207939]\n"
     ]
    }
   ],
   "source": [
    "print(f\"orginal :  {X_tr_n.shape[1]}\")\n",
    "print(f\"reduced: {X_tr_pca.shape[1]}\")\n",
    "print(f\"explained variance: {pca.explained_variance}\")\n",
    "print(f\"cumulative variance: {np.cumsum(pca.explained_variance)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40fdd289-690c-4850-8504-dec2bdbbd766",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, learning_rate=0.001, lambda_param=0.01, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.lambda_param = lambda_param\n",
    "        self.n_iters = n_iters\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        y_ = np.where(y <= 0, -1, 1)\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "        \n",
    "        for _ in range(self.n_iters):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                condition = y_[idx] * (np.dot(x_i, self.w) - self.b) >= 1\n",
    "                if condition:\n",
    "                    self.w -= self.lr * (2 * self.lambda_param * self.w)\n",
    "                else:\n",
    "                    self.w -= self.lr * (2 * self.lambda_param * self.w - np.dot(x_i, y_[idx]))\n",
    "                    self.b -= self.lr * y_[idx]\n",
    "                    \n",
    "    def predict(self, X):\n",
    "        approx = np.dot(X, self.w) - self.b\n",
    "        return np.sign(approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41980c83-6d4d-4f39-ab2c-6347efcf194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_no_pca = SVM(learning_rate=0.001, lambda_param=0.01, n_iters=1000)\n",
    "svm_no_pca.fit(X_tr_n, y_tr)\n",
    "y_pred_svm_no_pca = svm_no_pca.predict(X_te_n)\n",
    "y_pred_svm_no_pca = np.where(y_pred_svm_no_pca == -1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6363a0d-ebeb-48f8-ab2c-6bf093efb26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_svm_no_pca = accuracy(y_te, y_pred_svm_no_pca)\n",
    "prec_svm_no_pca = precision(y_te, y_pred_svm_no_pca)\n",
    "rec_svm_no_pca = recall(y_te, y_pred_svm_no_pca)\n",
    "f1_svm_no_pca = f1_score(y_te, y_pred_svm_no_pca)\n",
    "cm_svm_no_pca = confusion_matrix(y_te, y_pred_svm_no_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdfc2688-6243-4948-b654-5e9f3946a032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8101 (81.01%)\n",
      "precision: 0.7541\n",
      "recall:    0.7077\n",
      "F1:  0.7302\n",
      "\n",
      "confusion matrix:\n",
      "[[99 15]\n",
      " [19 46]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy:  {acc_svm_no_pca:.4f} ({acc_svm_no_pca*100:.2f}%)\")\n",
    "print(f\"precision: {prec_svm_no_pca:.4f}\")\n",
    "print(f\"recall:    {rec_svm_no_pca:.4f}\")\n",
    "print(f\"F1:  {f1_svm_no_pca:.4f}\")\n",
    "print(\"\\nconfusion matrix:\")\n",
    "print(cm_svm_no_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e34af3ca-7ccf-4cd0-8d29-f6063b1daecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM WITH PCA\n",
      "\n",
      "accuracy:  0.8101 (81.01%)\n",
      "precision: 0.7541\n",
      "recall:    0.7077\n",
      "f1:  0.7302\n",
      "\n",
      "confusion matrix:\n",
      "[[99 15]\n",
      " [19 46]]\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM WITH PCA\\n\")\n",
    "\n",
    "svm_with_pca = SVM(learning_rate=0.001, lambda_param=0.01, n_iters=1000)\n",
    "svm_with_pca.fit(X_tr_pca, y_tr)\n",
    "y_pred_svm_pca = svm_with_pca.predict(X_te_pca)\n",
    "y_pred_svm_pca = np.where(y_pred_svm_pca == -1, 0, 1)\n",
    "\n",
    "acc_svm_pca = accuracy(y_te, y_pred_svm_pca)\n",
    "prec_svm_pca = precision(y_te, y_pred_svm_pca)\n",
    "rec_svm_pca = recall(y_te, y_pred_svm_pca)\n",
    "f1_svm_pca = f1_score(y_te, y_pred_svm_pca)\n",
    "cm_svm_pca = confusion_matrix(y_te, y_pred_svm_pca)\n",
    "\n",
    "print(f\"accuracy:  {acc_svm_pca:.4f} ({acc_svm_pca*100:.2f}%)\")\n",
    "print(f\"precision: {prec_svm_pca:.4f}\")\n",
    "print(f\"recall:    {rec_svm_pca:.4f}\")\n",
    "print(f\"f1:  {f1_svm_pca:.4f}\")\n",
    "print(\"\\nconfusion matrix:\")\n",
    "print(cm_svm_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b18e05-1dae-47d4-b9ce-d64f077e607d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb8955c4-609a-404d-9235-19cc3e42a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sane results with or w/o pca in svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9d8281b-4229-4912-bebb-3778951921a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg:\n",
    "    def __init__(self, lr=0.01, itr=1000):\n",
    "        self.lr = lr\n",
    "        self.itr = itr\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.loss = []\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n = X.shape[0]\n",
    "        m = X.shape[1]\n",
    "        self.w = np.zeros(m)\n",
    "        self.b = 0\n",
    "        \n",
    "        for i in range(self.itr):\n",
    "            z = np.dot(X, self.w) + self.b\n",
    "            yp = self.sigmoid(z)\n",
    "            dw = (1/n) * np.dot(X.T, (yp - y))\n",
    "            db = (1/n) * np.sum(yp - y)\n",
    "            self.w -= self.lr * dw\n",
    "            self.b -= self.lr * db\n",
    "            l = -(1/n) * np.sum(y * np.log(yp + 1e-8) + (1 - y) * np.log(1 - yp + 1e-8))\n",
    "            self.loss.append(l)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        z = np.dot(X, self.w) + self.b\n",
    "        return self.sigmoid(z)\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        return (self.predict_proba(X) >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47b6e2d3-bac6-4ffd-bc96-8dcbf43236e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOGISTIC REGRESSION WITHOUT PCA\n",
      "\n",
      "accuracy:  0.8156 (81.56%)\n",
      "precision: 0.7667\n",
      "recall:    0.7077\n",
      "f1:  0.7360\n",
      "\n",
      "confusion matrix:\n",
      "[[100  14]\n",
      " [ 19  46]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLOGISTIC REGRESSION WITHOUT PCA\\n\")\n",
    "\n",
    "logreg_no_pca = LogReg(lr=0.1, itr=2000)\n",
    "logreg_no_pca.fit(X_tr_n, y_tr)\n",
    "y_pred_logreg_no_pca = logreg_no_pca.predict(X_te_n)\n",
    "\n",
    "acc_logreg_no_pca = accuracy(y_te, y_pred_logreg_no_pca)\n",
    "prec_logreg_no_pca = precision(y_te, y_pred_logreg_no_pca)\n",
    "rec_logreg_no_pca = recall(y_te, y_pred_logreg_no_pca)\n",
    "f1_logreg_no_pca = f1_score(y_te, y_pred_logreg_no_pca)\n",
    "cm_logreg_no_pca = confusion_matrix(y_te, y_pred_logreg_no_pca)\n",
    "\n",
    "print(f\"accuracy:  {acc_logreg_no_pca:.4f} ({acc_logreg_no_pca*100:.2f}%)\")\n",
    "print(f\"precision: {prec_logreg_no_pca:.4f}\")\n",
    "print(f\"recall:    {rec_logreg_no_pca:.4f}\")\n",
    "print(f\"f1:  {f1_logreg_no_pca:.4f}\")\n",
    "print(\"\\nconfusion matrix:\")\n",
    "print(cm_logreg_no_pca)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32c4cbaf-79af-4359-b9fd-cf0d5cfafde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOGISTIC REGRESSION WITH PCA\n",
      "\n",
      "accuracy:  0.8324 (83.24%)\n",
      "precision: 0.7692\n",
      "recall:    0.7692\n",
      "f1:  0.7692\n",
      "\n",
      "confusion matrix:\n",
      "[[99 15]\n",
      " [15 50]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\nLOGISTIC REGRESSION WITH PCA\\n\")\n",
    "\n",
    "logreg_pca = LogReg(lr=0.1, itr=2000)\n",
    "logreg_pca.fit(X_tr_pca, y_tr)\n",
    "y_pred_logreg_pca = logreg_pca.predict(X_te_pca)\n",
    "\n",
    "acc_logreg_pca = accuracy(y_te, y_pred_logreg_pca)\n",
    "prec_logreg_pca = precision(y_te, y_pred_logreg_pca)\n",
    "rec_logreg_pca = recall(y_te, y_pred_logreg_pca)\n",
    "f1_logreg_pca = f1_score(y_te, y_pred_logreg_pca)\n",
    "cm_logreg_pca = confusion_matrix(y_te, y_pred_logreg_pca)\n",
    "\n",
    "print(f\"accuracy:  {acc_logreg_pca:.4f} ({acc_logreg_pca*100:.2f}%)\")\n",
    "print(f\"precision: {prec_logreg_pca:.4f}\")\n",
    "print(f\"recall:    {rec_logreg_pca:.4f}\")\n",
    "print(f\"f1:  {f1_logreg_pca:.4f}\")\n",
    "print(\"\\nconfusion matrix:\")\n",
    "print(cm_logreg_pca)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6453f4f-ca30-49e0-a1a5-945d5f5f2b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
